\input{../utils/preamble}
\createdgmtitle{14}

\usepackage{tikz}

\usetikzlibrary{arrows,shapes,positioning,shadows,trees}
%--------------------------------------------------------------------------------
\begin{document}
%--------------------------------------------------------------------------------
\begin{frame}[noframenumbering,plain]
%\thispagestyle{empty}
\titlepage
\end{frame}
%=======
\begin{frame}{Outline}
	\tableofcontents
\end{frame}
%=======
\begin{frame}{Recap of previous lecture}
	\begin{figure}
		\centering
		\includegraphics[width=0.7\linewidth]{figs/cfm_uncond_to_cond}
	\end{figure}
	\vspace{-0.3cm}
	\begin{block}{Constraints}
		\vspace{-0.3cm}
		\[
			p(\bx) = \cN(0, \bI) = \bbE_{p(\bz)} p_0(\bx | \bz); \quad \pi(\bx) = \bbE_{p(\bz)} p_1(\bx | \bz).
		\]
		\vspace{-0.5cm}
	\end{block}
	\begin{itemize}
		\item How to choose the conditioning latent variable $\bz$?
		\item How to define $p_t(\bx | \bz)$ which follows the constraints?
	\end{itemize}
	\begin{block}{Gaussian conditional probability path}
		\vspace{-0.3cm}
		\[
			p_t(\bx | \bz) = \cN\left(\bmu_t(\bz), \bsigma_t^2(\bz)\right)
		\]
		\[
			\bx_t = \bmu_t(\bz) + \bsigma_t(\bz) \odot \bx_0, \quad {\color{violet} \bx_0 \sim p_0(\bx) = \cN(0, \bI)}
		\]
	\end{block}
		\myfootnotewithlink{https://dl.heeere.com/conditional-flow-matching/blog/conditional-flow-matching}{image credit: A Visual Dive into Conditional Flow Matching}
\end{frame}
%=======
\begin{frame}{Recap of previous lecture}
	\begin{block}{Gaussian conditional probability path}
		\vspace{-0.3cm}
		\[
			p_t(\bx | \bz) = \cN\left(\bmu_t(\bz), \bsigma_t^2(\bz)\right); \quad \bx_t = \bmu_t(\bz) + \bsigma_t(\bz) \odot \bx_0
		\]
		\vspace{-0.3cm}
		\[
			\bff(\bx, \bz, t) =  \bmu_t'(\bz) + \frac{\bsigma_t'(\bz)}{\bsigma_t(\bz)} \odot (\bx - \bmu_t(\bz))
		\]
		\vspace{-0.3cm}
	\end{block}
	\begin{block}{Conditioning latent variable}
		Let choose $\bz = \bx_1$. Then $p(\bz) = p_1(\bx_1)$.
		\[
			p_t(\bx) = \int p_t(\bx | \bx_1) p_1(\bx_1) d \bx_1
		\]
		\vspace{-0.5cm}
	\end{block}
	We need to ensure boundary constraints:
	\[
		\begin{cases}
			p(\bx) = \bbE_{p(\bz)} p_0(\bx | \bz); {\color{gray}(= \cN(0, \bI))} \\
			\pi(\bx) = \bbE_{p(\bz)} p_1(\bx | \bz).
		\end{cases}
		\quad \Rightarrow \quad 
		\begin{cases}
			p_0(\bx | \bx_1) = \cN(0, \bI); \\
			p_1(\bx | \bx_1) = \delta(\bx - \bx_1).
		\end{cases}
	\]
	\vspace{-0.3cm}
	\myfootnotewithlink{https://arxiv.org/abs/2210.02747}{Lipman Y., et al. Flow Matching for Generative Modeling, 2022}
\end{frame}
%=======
\begin{frame}{Recap of previous lecture}
	\[
		p_0(\bx | \bx_1) = \cN(0, \bI); \quad p_1(\bx | \bx_1) = \delta(\bx - \bx_1).
	\]
	
	\begin{block}{Gaussian conditional probability path}
		\vspace{-0.5cm}
		\[
			p_t(\bx | \bx_1) = \cN\left(\bmu_t(\bx_1), \bsigma_t^2(\bx_1)\right); \quad \bx_t = \bmu_t(\bx_1) +  \bsigma_t(\bx_1) \odot \bx_0.
		\]
		\vspace{-0.6cm}
	\end{block}
	Let consider straight conditional paths	
	\[
		\begin{cases}
			\bmu_t(\bx_1) = t \bx_1; \\
			\bsigma_t(\bx_1) = 1 - t.
		\end{cases}
		\quad \Rightarrow \quad 
		\begin{cases}
			p_t(\bx | \bx_1) = \cN\left(t \bx_1, (1-t)^2 \bI\right); \\
		 	\bx_t = t \bx_1 + (1 - t) \bx_0. 
	 \end{cases}
	\]
	\vspace{-0.3cm}
	\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{figs/conical_paths}
	\end{figure}
	\myfootnotewithlink{https://dl.heeere.com/conditional-flow-matching/blog/conditional-flow-matching}{image credit: A Visual Dive into Conditional Flow Matching}
\end{frame}
%=======
\section{Latent space models}
%=======
\subsection{Score-based models}
%=======
\begin{frame}{Latent space models}
	\begin{block}{Score-based models (diffusion)}
		\vspace{-0.3cm}
		\begin{figure}
			\includegraphics[width=\linewidth]{figs/latent_diffusion}
		\end{figure}
		\vspace{-0.3cm}
	\end{block}
	\begin{block}{Flow matching}
		\vspace{-0.3cm}
		\begin{figure}
			\includegraphics[width=\linewidth]{figs/latent_flow_matching}
		\end{figure}
	\end{block}

	\myfootnote{\href{https://arxiv.org/abs/2307.08698}{Dao Q. et al. Flow Matching in Latent Space, 2023} \\ \href{https://neurips2023-ldm-tutorial.github.io/}{NeurIPS 2023 Tutorial: Latent Diffusion Models: Is the Generative AI Revolution Happening in Latent Space?}}
\end{frame}
%=======
\subsection{Autoregressive models}
%=======
\begin{frame}{Vector Quantized VAE (VQ-VAE) }
	\begin{block}{Vector quantization}
		Define the dictionary space $\{\be_k\}_{k=1}^K$, where $\be_k \in \bbR^C$, $K$ is the size of the dictionary.
		\vspace{-0.5cm}
		\begin{minipage}[t]{0.45\columnwidth}
			\[
				\bz_q = \bq (\bz) = \be_{k^*}
			\] 
			Here $k^* = \argmin_k \| \bz - \be_k \|$.
		\end{minipage}%
		\begin{minipage}[t]{0.55\columnwidth}
			\vspace{-0.5cm}
			\begin{figure}
				\includegraphics[width=\linewidth]{figs/fqgan_cnn}
			\end{figure}
		\end{minipage}		
	\end{block}
	\[
		\cL_{\bphi, \btheta}(\bx)  =  \log p(\bx | \bz_q, \btheta) - \log K
	\]
	\vspace{-0.5cm}
	\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{figs/vqvae}
	\end{figure}
	\myfootnote{\href{https://arxiv.org/abs/2004.02088}{Zhao Y. et al. Feature Quantization Improves GAN Training, 2020} \\ \href{https://arxiv.org/abs/1711.00937}{Oord A., Vinyals O., Kavukcuoglu K. Neural Discrete Representation Learning, 2017}}
\end{frame}
%=======
\begin{frame}{Vector Quantized GAN}
	\begin{itemize}
		\item Use VQVAE model and objective.
		\item Add adversarial loss between generated and real images to improve the visual quality of the reconstructions.
	\end{itemize}
	\begin{figure}
		\includegraphics[width=\linewidth]{figs/vqgan}
	\end{figure}
	
	\myfootnotewithlink{https://arxiv.org/abs/2012.09841}{Esser P. et al. Taming Transformers for High-Resolution Image Synthesis, 2020}
\end{frame}
%=======
\begin{frame}{LlamaGen: pure autoregression}
	\begin{itemize}
		\item Use VQGAN encoder to map images to the discrete latent space of the codebook vectors.
		\item Learn the pure autoregression model (Llama-based) in the latent space.
		\item Use VQGAN decoder to map the discrete space tokens to the image space.
	\end{itemize}
	\begin{figure}
		\includegraphics[width=0.9\linewidth]{figs/llamagen_samples}
	\end{figure}
	
	\myfootnotewithlink{https://arxiv.org/pdf/2406.06525}{Sun P. et al. Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation, 2024}
\end{frame}
%=======
\begin{frame}{Visual Autoregressive Modeling (VAR)}
	\begin{figure}
		\includegraphics[width=\linewidth]{figs/var_idea}
	\end{figure}
	\begin{figure}
		\includegraphics[width=\linewidth]{figs/var_training}
	\end{figure}
	\myfootnotewithlink{https://arxiv.org/pdf/2404.02905}{Tean K. et al. Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction, 2024}
\end{frame}
%=======
\section{The worst course overview}
%=======
\begin{frame}{The worst course overview :)}
	\begin{figure}
		\includegraphics[width=\linewidth]{figs/generative-overview}
	\end{figure}
	\myfootnotewithlink{https://lilianweng.github.io/posts/2021-07-11-diffusion-models/}{Weng L. What are Diffusion Models?, blog post, 2021}
\end{frame}
%=======
\begin{frame}{The worst course overview :)}
	\vspace{-0.3cm}
	\begin{figure}
		\includegraphics[width=0.45\linewidth]{figs/trilemma}
	\end{figure}
	\vspace{-0.5cm}
	\begin{figure}
		\includegraphics[width=0.9\linewidth]{figs/gen_comp_table}
	\end{figure}
	\myfootnote{\href{https://arxiv.org/abs/2112.07804}{Xiao Z., Kreis K., Vahdat A. Tackling the generative learning trilemma with denoising diffusion GANs, 2021} \\ \href{https://udlbook.github.io/udlbook/}{Simon J.D. Prince. Understanding Deep Learning, 2023}}
\end{frame}
%=======
\begin{frame}{Summary}
	\begin{itemize}
		\item Most of the state-of-the-art generative models are latent models with continuous or discrete latent space.
	\end{itemize}
\end{frame}
\end{document} 