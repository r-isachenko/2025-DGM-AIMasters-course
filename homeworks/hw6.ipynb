{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZXJoDiD_x-N"
   },
   "source": [
    "# Homework6: Flow matching models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxF8ewFXn1HO",
    "tags": []
   },
   "source": [
    "## Task 1: Theory (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFn6d3vkuZIl"
   },
   "source": [
    "### Problem 1: KFP theorem (1pt)\n",
    "\n",
    "We have faced with 2 different formulations of Kolmogorov-Fokker-Planck theorem.\n",
    "\n",
    "1) continuity equation in continuous-in-time NF:\n",
    "$$\n",
    "\\frac{d \\log p(\\mathbf{x}(t), t)}{d t} = - \\text{tr} \\left( \\frac{\\partial f(\\mathbf{x}, t)}{\\partial \\mathbf{x}} \\right);\n",
    "$$\n",
    "\n",
    "2) the general form of the KFP equation in SDEs:\n",
    "$$\n",
    "\\frac{\\partial p(\\mathbf{x}, t)}{\\partial t} = - \\text{div}\\left(\\mathbf{f}(\\mathbf{x}, t) p(\\mathbf{x}, t)\\right) + \\frac{1}{2} g^2(t) \\Delta p(\\mathbf{x}, t).\n",
    "$$\n",
    "\n",
    "In this task your goal is to prove that the first formulation is a special case of the more general second formulation.\n",
    "\n",
    "**Note:** The derivation in the first formulation is total derivative (not partial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbxPyzwcuinj"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: DDPM as SDE discretization (2pt)\n",
    "\n",
    "We have proved that DDPM is a discretization of the SDE\n",
    "$$\n",
    "\td \\mathbf{x} = - \\frac{1}{2} \\beta(t) \\mathbf{x}(t) dt + \\sqrt{\\beta(t)} \\cdot d \\mathbf{w}.\n",
    "$$\n",
    "Here $\\mathbf{f}(\\mathbf{x}, t) = - \\frac{1}{2} \\beta(t) \\mathbf{x}(t)$, $g(t) = \\sqrt{\\beta(t)}$.\n",
    "\n",
    "Recall reverse SDE\n",
    "$$\n",
    "    d\\mathbf{x} = \\left(\\mathbf{f}(\\mathbf{x}, t) - g^2(t) \\frac{\\partial \\log p_t(\\mathbf{x})}{\\partial \\mathbf{x}}\\right) dt + g(t) d \\mathbf{w}.\n",
    "$$\n",
    "\n",
    "The reverse SDE of the DDPM model will be\n",
    "$$\n",
    "    d\\mathbf{x}(t) = -\\beta(t)\\left[\\frac{x(t)}{2} + \\nabla_{\\mathbf{x}}\\log p_t(\\mathbf{x}(t))\\right]dt + \\sqrt{\\beta(t)}d\\mathbf{w}.\n",
    "$$\n",
    "\n",
    "The DDPM uses the following form of ancestral sampling\n",
    "$$\n",
    "\\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{1 - \\beta_t}} \\cdot \\mathbf{x}_t + \\frac{\\beta_t}{\\sqrt{1 - \\beta_t}} \\cdot \\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{x}_t | \\boldsymbol{\\theta}) +  \\sqrt{\\beta_t} \\cdot \\boldsymbol{\\epsilon}.\n",
    "$$\n",
    "(Here we assumed that $p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta}) = \\mathcal{N} \\left(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t), \\beta_t \\cdot \\mathbf{I}\\right)$).\n",
    "\n",
    "Here is your task to validate that DDPM iterative update scheme is actually discretization of SDE by letting $t \\in \\{0,\\ldots,\\frac{N-1}{N}\\}$, $\\Delta t = 1/N$, $\\mathbf{x}(t-\\Delta t) = \\mathbf{x}_{s-s}$, $\\mathbf{x}(t) = \\mathbf{x}_s$, and $\\beta(t)\\Delta t = \\beta_s$, s.e.:\n",
    "\n",
    "In this task your goal is to show that the ancestral sampling is a discretization of the DDPM reverse SDE.\n",
    "\n",
    "**Hints**:\n",
    "1. use $dt < 0$;\n",
    "2. $\\beta_t = - \\beta(t) dt$;\n",
    "3. $d\\mathbf{w} = \\boldsymbol{\\epsilon} \\cdot \\sqrt{-dt}$;\n",
    "4. drop the terms with the order of $o(dt)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Covariance of the Forward SDE (2pt)\n",
    "\n",
    "From [lecture 12](https://github.com/r-isachenko/2025-DGM-AIMasters-course/blob/main/lectures/lecture12/Lecture12.pdf) we know that the forward SDE\n",
    "\n",
    "$$\n",
    "d\\mathbf{x}= \\mathbf{f}(\\mathbf{x},t)\\,dt + g(t)\\,d\\mathbf{w}\n",
    "$$\n",
    "\n",
    "has conditional moments\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt}\\mu\\bigl(\\mathbf{x}(t),\\mathbf{x}(0)\\bigr)\n",
    " = \\mathbb{E}\\bigl[\\mathbf{f}\\bigl(\\mathbf{x}(t),t\\bigr)\\mid\\mathbf{x}(0)\\bigr],\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt}\\Sigma\\bigl(\\mathbf{x}(t),\\mathbf{x}(0)\\bigr)\n",
    " = \\mathbb{E}\\bigl[\\mathbf{f}\\,(\\mathbf{x}(t)-\\mu)^{\\top}+(\\mathbf{x}(t)-\\mu)\\mathbf{f}^{\\top}\\mid\\mathbf{x}(0)\\bigr] + g^{2}(t)\\mathbf{I}.\n",
    "$$\n",
    "\n",
    "Your goal is to prove the covariance identity shown above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41370,
     "status": "ok",
     "timestamp": 1700068971438,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "nYZ__zsi3McN",
    "outputId": "1153bb7c-f9cd-4a0f-83bd-e2827f989f53",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COMMIT_HASH = \"3d42df9f2a21a7109510d6829e8b05d7f71fa3ac\"\n",
    "!if [ -d dgm_utils ]; then rm -Rf dgm_utils; fi\n",
    "!git clone https://github.com/r-isachenko/dgm_utils.git\n",
    "%cd dgm_utils\n",
    "!git checkout {COMMIT_HASH}\n",
    "!pip install ./\n",
    "%cd ./..\n",
    "!rm -Rf dgm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mC57wAo5Yag"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dgm_utils import load_dataset, BaseModel, train_model\n",
    "from dgm_utils import visualize_images, show_samples, LabeledDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1700068977911,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "grmP96FjfQZg",
    "outputId": "19c07923-08ff-45a4-e607-34e3c5bc325e"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import ot as pot\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torchdiffeq import odeint\n",
    "from torch_ema import ExponentialMovingAverage as EMA\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    print('GPU found :)') \n",
    "else: \n",
    "    DEVICE = \"cpu\"\n",
    "    print('GPU not found :(')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Flow matching on MNIST (4 pt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will train **Flow matching** model, focusing on its sampling capabilities. See the [lecture 12](https://github.com/r-isachenko/2025-DGM-AIMasters-course/blob/main/lectures/lecture12/Lecture12.pdf), [seminar 12](https://github.com/r-isachenko/2025-DGM-AIMasters-course/blob/main/seminars/seminar12/seminar_12_adapters.ipynb) and [paper](https://arxiv.org/abs/2210.02747) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset(\"mnist\", flatten=False, binarize=False)\n",
    "visualize_images(train_data, \"MNIST samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous homework and Seminar 8 we will use UNet, that is also a standart choice for flow matching models. The model will be mostly implemented, but you could change it if you want. \n",
    "\n",
    "First, we'll define time embedding block for our UNet architecture. `TimeEmbedding` - creates sinusoidal position embeddings for timesteps, allowing the model to understand which diffusion step it's processing.\n",
    "\n",
    "**Note:** it now takes any float value from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0\n",
    "        self.dim = dim\n",
    "        self.register_buffer('freqs', torch.arange(1, dim // 2 + 1) * torch.pi)\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        emb = self.freqs * t.unsqueeze(-1)\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UNet's core component is the `ResBlock`, which enhances standard ResNet blocks with time step embeddings and optional attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_dim: int):\n",
    "        super().__init__()\n",
    "        self.group_norm = nn.GroupNorm(32, in_dim)\n",
    "        self.proj_q = nn.Conv2d(in_dim, in_dim, kernel_size=1, stride=1, padding=0)\n",
    "        self.proj_k = nn.Conv2d(in_dim, in_dim, kernel_size=1, stride=1, padding=0)\n",
    "        self.proj_v = nn.Conv2d(in_dim, in_dim, kernel_size=1, stride=1, padding=0)\n",
    "        self.proj = nn.Conv2d(in_dim, in_dim, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.group_norm(x)\n",
    "        q = self.proj_q(h)\n",
    "        k = self.proj_k(h)\n",
    "        v = self.proj_v(h)\n",
    "        \n",
    "        q = q.permute(0, 2, 3, 1).view(B, H * W, C) \n",
    "        k = k.view(B, C, H * W)\n",
    "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
    "        assert list(w.shape) == [B, H * W, H * W]\n",
    "        w = F.softmax(w, dim=-1)\n",
    "        \n",
    "        v = v.permute(0, 2, 3, 1).view(B, H * W, C) \n",
    "        h = torch.bmm(w, v)\n",
    "        assert list(h.shape) == [B, H * W, C]\n",
    "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "        h = self.proj(h)\n",
    "        \n",
    "        return x + h\n",
    "    \n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, t_dim, dropout, attn=False):\n",
    "        super().__init__()\n",
    "        self.temb_proj = nn.Sequential(Swish(), nn.Linear(t_dim, out_channels))\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # create two convolutional blocks of nn.Sequential\n",
    "        # first block should take raw input\n",
    "        # second block should take the output of the first block with added time and class embeddings\n",
    "        # it is preferrable to use nn.GroupNorm, Swish and nn.Dropout\n",
    "\n",
    "        # ====\n",
    "\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
    "        self.attn = AttnBlock(out_channels) if attn else nn.Identity()\n",
    "\n",
    "    \n",
    "    def forward(self, x, temb):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) pass x through the first block\n",
    "        # 2) add time and class embeddings (unsqueeze them to the right shape)\n",
    "        # 3) pass the result through the second block\n",
    "        # 4) add the shortcut\n",
    "        # 5) pass the result through the attention block\n",
    "\n",
    "        # ====\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DownsampleBlock` and `UpsampleBlock` implement the UNet's characteristic encoder-decoder structure, managing resolution changes as features flow through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleBlock(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super().__init__()\n",
    "        # ====\n",
    "        # your code \n",
    "        # define convolutional layer that:\n",
    "        # 1) does not change the number of channels\n",
    "        # 2) reduces the size of the image twice\n",
    "\n",
    "        # ====\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor, *args) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "\n",
    "        # ====\n",
    "        return x\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super().__init__()\n",
    "        # ====\n",
    "        # your code \n",
    "        # define convolutional layer that:\n",
    "        # 1) does not change the number of channels\n",
    "        # 2) does not reduce the size of the image\n",
    "\n",
    "        # ====\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor, *args) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) upsample the input tensor using bilinear interpolation\n",
    "        # 2) pass the result through the convolutional layer\n",
    "\n",
    "        # ====\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define the complete `UNet` - the neural network backbone of our flow matching model that handles both encoding and decoding with skip connections. Look at the code carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        hidden_channels: int, \n",
    "        channel_multipliers: List[int], \n",
    "        num_blocks: int = 2,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        temb_dim = hidden_channels * 4\n",
    "        self.time_embedding = TimeEmbedding(temb_dim)\n",
    "        self.head = nn.Conv2d(1, hidden_channels, kernel_size=3, stride=1, padding=1)\n",
    "        channel_list, curr_channels = [hidden_channels], hidden_channels\n",
    "\n",
    "        # initialization of downsample blocks\n",
    "        self.downsample_blocks = nn.ModuleList()\n",
    "        for idx, scale in enumerate(channel_multipliers):\n",
    "            out_channels = hidden_channels * scale\n",
    "            is_last = (idx == len(channel_multipliers) - 1)\n",
    "\n",
    "            # make multiple ResBlocks at each scale\n",
    "            for _ in range(num_blocks):\n",
    "                # at each channel_multipliers scale we add ResBlock\n",
    "                # last block has attention\n",
    "                self.downsample_blocks.append(\n",
    "                    ResBlock(curr_channels, out_channels, temb_dim, dropout, attn=True)\n",
    "                )\n",
    "                curr_channels = out_channels\n",
    "                channel_list.append(curr_channels)\n",
    "\n",
    "            # add downsample block if not last block\n",
    "            if not is_last:\n",
    "                self.downsample_blocks.append(DownsampleBlock(curr_channels))\n",
    "                channel_list.append(curr_channels)\n",
    "        \n",
    "        # initialization of bottleneck block\n",
    "        self.bottleneck = nn.ModuleList([\n",
    "            ResBlock(curr_channels, curr_channels, temb_dim, dropout, attn=True),\n",
    "            ResBlock(curr_channels, curr_channels, temb_dim, dropout, attn=False)\n",
    "        ])\n",
    "        \n",
    "        # initialization of upsample blocks\n",
    "        self.upsample_blocks = nn.ModuleList()\n",
    "        for idx, scale in reversed(list(enumerate(channel_multipliers))):\n",
    "            out_channels = hidden_channels * scale\n",
    "            is_first, is_last = (idx == 0), (idx == len(channel_multipliers) - 1)\n",
    "\n",
    "            # make multiple ResBlocks at each scale\n",
    "            for _ in range(num_blocks + 1):\n",
    "                # at each reverse channel_multipliers scale we add ResBlock\n",
    "                # first block has attention\n",
    "                self.upsample_blocks.append(\n",
    "                    ResBlock(channel_list.pop() + curr_channels, out_channels, temb_dim, dropout, attn=False)\n",
    "                )\n",
    "            \n",
    "                curr_channels = out_channels\n",
    "            \n",
    "            # add upsample block if not last block\n",
    "            if not is_first:\n",
    "                self.upsample_blocks.append(UpsampleBlock(curr_channels))\n",
    "                \n",
    "        self.tail = nn.Sequential(\n",
    "            nn.GroupNorm(32, curr_channels),\n",
    "            Swish(),\n",
    "            nn.Conv2d(curr_channels, 1, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        temb = self.time_embedding(t)\n",
    "\n",
    "        h = self.head(x)\n",
    "        skip_connections = [h] # save intermediate results for skip connections\n",
    "\n",
    "        # downsample\n",
    "        for layer in self.downsample_blocks:\n",
    "            h = layer(h, temb)\n",
    "            skip_connections.append(h) # save intermediate results for skip connections\n",
    "\n",
    "        # bottleneck\n",
    "        for layer in self.bottleneck:\n",
    "            h = layer(h, temb)\n",
    "        \n",
    "        # upsample\n",
    "        for layer in self.upsample_blocks:\n",
    "            if isinstance(layer, ResBlock): # apply skip connection\n",
    "                skip_connection = skip_connections.pop()\n",
    "                h = torch.cat([h, skip_connection], dim=1)\n",
    "            h = layer(h, temb)\n",
    "\n",
    "        h = self.tail(h)\n",
    "        return h\n",
    "\n",
    "def test_unet():\n",
    "    model = UNet(hidden_channels=128, channel_multipliers=[1, 2, 4])\n",
    "    x = torch.rand((2, 1, 32, 32))\n",
    "    t = torch.zeros(size=(2,), dtype=torch.long)\n",
    "    out1 = model(x, t)\n",
    "    t = torch.ones(size=(2,), dtype=torch.long)\n",
    "    out2 = model(x, t)\n",
    "    assert not np.allclose(out1.detach().numpy(), out2.detach().numpy())\n",
    "\n",
    "\n",
    "test_unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conditional flow matching, our objective is to learn a vector field $ f_\\theta(\\mathbf{x}; t) $, parameterized by a neural network, that aligns with a known target vector field $f(\\mathbf{x}; \\mathbf{x}_1, t)$ at each point along a path connecting the data distribution and a base distribution. So, the training objective is defined as:\n",
    "\n",
    "$$\n",
    "\\min_\\theta\\, \\mathbb{E}_{t \\sim U[0, 1]}\\, \\mathbb{E}_{\\mathbf{x}_1 \\sim p(\\mathbf{x}_1)} \\mathbb{E}_{\\mathbf{x} \\sim p_t(\\mathbf{x} | \\mathbf{x}_1)} \\left[ \\left\\| f(\\mathbf{x}; \\mathbf{x}_1, t) - f_\\theta(\\mathbf{x}; t) \\right\\|^2 \\right],\n",
    "$$\n",
    "\n",
    "In this task, we consider the **optimal transport conditional vector field**, defined by:\n",
    "$$\n",
    "f(\\mathbf{x}; \\mathbf{x}_1, t) = \\frac{d\\mathbf{x}}{dt} = \\frac{\\mathbf{x}_1 - \\mathbf{x}}{1 - t},\n",
    "$$\n",
    "which means that $\\mathbf{x}$ iterpolates linearly by making data more noisy:\n",
    "$$\n",
    "\\mathbf{x}_t = t \\mathbf{x}_1 + (1 - t) \\mathbf{x}_0.\n",
    "$$\n",
    "\n",
    "Now, let's define the architecture of the Flow matching model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowMatchingModel(BaseModel):\n",
    "    def __init__(\n",
    "        self, \n",
    "        hidden_channels: int, \n",
    "        channel_multipliers: List[int],\n",
    "        num_blocks: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = UNet(\n",
    "            hidden_channels=hidden_channels, \n",
    "            channel_multipliers=channel_multipliers, \n",
    "            num_blocks=num_blocks\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        return self.model(x, t)\n",
    "\n",
    "    def loss(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        y: Optional[torch.Tensor] = None\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        if y is None:\n",
    "            y = torch.randn_like(x, device=self.device)\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) sample time uniformly from 0 to 1\n",
    "        # 2) calculate x_t and optimal flow\n",
    "        # 3) predict flow using model\n",
    "        # 4) calculate loss\n",
    "\n",
    "        # ====\n",
    "        return {'total_loss': loss}\n",
    "\n",
    "    def odefunc(self, t: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self(x, torch.full(x.shape[:1], t, device=self.device))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "        self, \n",
    "        n: Optional[int] = None, \n",
    "        num_steps: int = 100, \n",
    "        y: Optional[torch.Tensor] = None\n",
    "    ) -> np.ndarray:\n",
    "        if y is None:\n",
    "            assert n is not None, \"Either n or y should be provided!\"\n",
    "            y = torch.randn(n, 1, 32, 32, device=self.device)  # Start with noise\n",
    "        else:\n",
    "            y = y.to(self.device)\n",
    "        \n",
    "        time_interval = torch.linspace(0.0, 1.0, num_steps, device=self.device)\n",
    "        # ====\n",
    "        # your code\n",
    "        # use odeint to sample from model\n",
    "        # NOTE: use fixed step solvers (e.g. euler), we will need for the task\n",
    "        # https://github.com/rtqichen/torchdiffeq/blob/master/FURTHER_DOCUMENTATION.md\n",
    "\n",
    "        # ====\n",
    "        samples = states[-1]  # Take the last state as the sample\n",
    "        return samples.cpu().clip(0, 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "LR = \n",
    "EPOCHS = \n",
    "HIDDEN_CHANNELS = \n",
    "CHANNEL_MULTIPLIERS = \n",
    "NUM_BLOCKS = \n",
    "# ====\n",
    "\n",
    "model = FlowMatchingModel(\n",
    "    hidden_channels=HIDDEN_CHANNELS, \n",
    "    channel_multipliers=CHANNEL_MULTIPLIERS,\n",
    "    num_blocks=NUM_BLOCKS,\n",
    ")\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "# choose any optimizer/scheduler as you want\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    n_samples=16,\n",
    "    visualize_samples=True,\n",
    ")\n",
    "\n",
    "# you might want to save the model\n",
    "# torch.save(model.state_dict(), \"flow_matching_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now sample images using different numbers of steps. With only 2 steps, the results are likely to be poor. In next tasks we will try to fix this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "num_samples = 100\n",
    "samples_2 = model.sample(n=num_samples, num_steps=2)\n",
    "samples_10 = model.sample(n=num_samples, num_steps=10)\n",
    "\n",
    "show_samples(samples_2, title=\"Samples with 2 steps\")\n",
    "show_samples(samples_10, title=\"Samples with 10 steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Rectified flow (2 pt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to address this issue is by fine-tuning the model using training pairs sampled from the model itself. This approach was introduced in Rectified Flow [paper](https://arxiv.org/abs/2209.03003). \n",
    "\n",
    "Specifically, the process involves first generating noise–image pairs $(\\mathbf{x}_0^*, \\mathbf{x}_1^*)$, which are then used to retrain the model. Mathematically speaking, for any convex cost function $c$ (e.g., $\\|\\cdot\\|^2$), the expected displacement under the generated pairs is smaller than that of the original data:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[c(\\mathbf{x}_1^* - \\mathbf{x}_0^*)] \\leq \\mathbb{E}[c(\\mathbf{x}_1 - \\mathbf{x}_0)].\n",
    "$$\n",
    "\n",
    "As a result, the ODE trajectories tend to be shorter and empirically more direct, which can improve numerical stability and reduce the number of steps required for accurate integration. This procedure could be repeated multilple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(\n",
    "    model: BaseModel,\n",
    "    num_steps: int,\n",
    "    batch_size: int,\n",
    "    train_size: int,\n",
    "    test_size: int,\n",
    ") -> Tuple[np.ndarray, ...]:\n",
    "    train_noise = torch.randn(train_size, 1, 32, 32)\n",
    "    test_noise = torch.randn(test_size, 1, 32, 32)\n",
    "\n",
    "    train_x = np.empty_like(train_noise)\n",
    "    test_x = np.empty_like(test_noise)\n",
    "    \n",
    "    # ====\n",
    "    # your code\n",
    "    # generate train and test samples\n",
    "\n",
    "    # ====\n",
    "\n",
    "    return train_x, train_noise, test_x, test_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might want to load the model\n",
    "# model.load_state_dict(torch.load(\"flow_matching_model.pth\"))\n",
    "\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "train_x, train_noise, test_x, test_noise = prepare_dataset(\n",
    "    model, \n",
    "    num_steps=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_size=len(train_data), \n",
    "    test_size=len(test_data)\n",
    ")\n",
    "train_data = LabeledDataset(train_x, train_noise)\n",
    "test_data = LabeledDataset(test_x, test_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fine-tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "LR = \n",
    "EPOCHS = \n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "# choose any optimizer/scheduler as you want\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    n_samples=16,\n",
    "    visualize_samples=True,\n",
    "    conditional=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you should obtain higher-quality images even with 2-step generation and similar with 10-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "num_samples = 100\n",
    "samples_2 = model.sample(n=num_samples, num_steps=2)\n",
    "samples_10 = model.sample(n=num_samples, num_steps=10)\n",
    "\n",
    "show_samples(samples_2, title=\"Samples with 2 steps\")\n",
    "show_samples(samples_10, title=\"Samples with 10 steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Flow matching with OT couplings (4 pt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to reduce displacement under a given cost function is through **optimal transport (OT)**. The goal is to ensure that the generated sample $\\mathbf{x}_1$ remains close to the original noise $\\mathbf{x}_0$, under a cost function $c(\\mathbf{x}_0, \\mathbf{x}_1)$, such as $\\|\\mathbf{x}_1 - \\mathbf{x}_0\\|^2$. This leads to minimizing the **Wasserstein distance** between the distributions:\n",
    "\n",
    "$$\n",
    "W(p_0, p_1) = \\inf_{\\pi \\in \\Pi(p_0, p_1)} \\mathbb{E}_{(\\mathbf{x}_0, \\mathbf{x}_1) \\sim \\pi}[\\|\\mathbf{x}_0 - \\mathbf{x}_1\\|^2],\n",
    "$$\n",
    "\n",
    "where $\\Pi(p_0, p_1)$ is the set of all couplings with marginals $p_0$ and $p_1$.\n",
    "\n",
    "In practice we skip the costly full-dataset OT and work inside each mini-batch. We treat the batch of images $ \\{\\mathbf{x}_0^{i}\\}_{i=1}^{B}$ and the batch of noise $ \\{\\mathbf{x}_1^{j}\\}_{j=1}^{B}$ as a vectors from uniform distributions $\\mathbf{a}$ and $\\mathbf{b}$. Next, we form the cost matrix $M_{ij} = \\|\\mathbf{x}_0^{i} - \\mathbf{x}_1^{j}\\|^{2}$ and find Wasserstein distance:\n",
    "\n",
    "$$\n",
    "\\pi^\\star = \\arg\\min_{\\pi \\in \\Pi(\\mathbf{a},\\mathbf{b})} \\langle \\pi, M \\rangle,\n",
    "$$\n",
    "\n",
    "to get the optimal transport plan $\\pi^\\star$.\n",
    "\n",
    "We then sample index pairs $(i,j)$ according to the weights in $\\pi^\\star$ and train on the matched pairs $(\\mathbf{x}_0^{i}, \\mathbf{x}_1^{j})$. This keeps each image close to a nearby noise point, shrinking the mini-batch Wasserstein distance. For more, see [paper](https://arxiv.org/abs/2304.14772).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset(\"mnist\", flatten=False, binarize=False)\n",
    "visualize_images(train_data, \"MNIST samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of coding an OT solver from scratch, we’ll rely on the [POT library](https://pythonot.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowMatchingOTModel(FlowMatchingModel):\n",
    "    def get_map(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) covert x and y to vectors\n",
    "        # 2) apply Earth Movers distance solver with L2 cost matrix\n",
    "        # NOTE: treat x and y as elements from uniform distribution\n",
    "       \n",
    "        # ====\n",
    "        return p\n",
    "\n",
    "    def sample_map(self, pi, batch_size):\n",
    "        p = pi.flatten()\n",
    "        p = p / p.sum()\n",
    "        choices = np.random.choice(pi.shape[0] * pi.shape[1], p=p, size=batch_size)\n",
    "        return np.divmod(choices, pi.shape[1])\n",
    "\n",
    "    def sample_plan(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        pi = self.get_map(x, y)\n",
    "        i, j = self.sample_map(pi, x.shape[0])\n",
    "        return x[i], y[j]\n",
    "\n",
    "    def loss(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        y: Optional[torch.Tensor] = None\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        if y is None:\n",
    "            y = torch.randn_like(x, device=self.device)\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) sample time uniformly from 0 to 1\n",
    "        # 2) permute x and y using OT\n",
    "        # 3) calculate x_t and optimal flow\n",
    "        # 4) predict flow using model\n",
    "        # 5) calculate loss\n",
    "        \n",
    "        # ====\n",
    "        return {'total_loss': loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "LR = \n",
    "EPOCHS = \n",
    "HIDDEN_CHANNELS = \n",
    "CHANNEL_MULTIPLIERS = \n",
    "NUM_BLOCKS = \n",
    "# ====\n",
    "\n",
    "model = FlowMatchingOTModel(\n",
    "    hidden_channels=HIDDEN_CHANNELS, \n",
    "    channel_multipliers=CHANNEL_MULTIPLIERS,\n",
    "    num_blocks=NUM_BLOCKS,\n",
    ")\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "# choose any optimizer/scheduler as you want\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    n_samples=16,\n",
    "    visualize_samples=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With just two steps, the samples should improve over the original Flow matching baseline, but they’ll still fall short of the quality achieved by Rectified flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "num_samples = 100\n",
    "samples_2 = model.sample(n=num_samples, num_steps=2)\n",
    "samples_10 = model.sample(n=num_samples, num_steps=10)\n",
    "\n",
    "show_samples(samples_2, title=\"Samples with 2 steps\")\n",
    "show_samples(samples_10, title=\"Samples with 10 steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
