{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76f79fa4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Deep Generative Models</center>\n",
    "## <center>Seminar 8</center>\n",
    "\n",
    "<center>10.04.2025</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac19ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Score matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff417d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"pics/score_matching.png\" width=1200 /></center>\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \\mathbb{E}_{\\pi} \\left\\| \\mathbf{s}_{\\theta}(\\mathbf{x}) - \\nabla_{\\mathbf{x}} \\log \\pi(\\mathbf{x}) \\right\\|_2^2 \\rightarrow \\min_{\\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6deeb1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Problem:** We don't know $\\pi(\\mathbf{x})$ ($p(\\mathbf{x})$ on picture) :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2147fb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Denoising score matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc1f9a9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead, we can train $\\mathbf{s}_{\\theta}$ on **noise distribution** $q(\\mathbf{x}_\\sigma) = \\int \\pi(\\mathbf{x}) q(\\mathbf{x}_\\sigma \\mid \\mathbf{x})$, where $q(\\mathbf{x}_\\sigma \\mid \\mathbf{x}) = \\mathcal{N}(\\mathbf{x}, \\sigma^2 \\mathbf{I})$, using only the known conditional distribution.\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \\mathbb{E}_{q(x_\\sigma)} \\left\\| \\mathbf{s}_{\\theta, \\sigma}(\\mathbf{x}_\\sigma) - \\nabla_{\\mathbf{x}_\\sigma} \\log q(\\mathbf{x}_\\sigma) \\right\\|_2^2 \\rightarrow \\min_{\\theta}\n",
    "$$\n",
    "$$\n",
    "\\downarrow\n",
    "$$\n",
    "$$\n",
    "\\frac{1}{2}\\mathbb{E}_{\\pi(x)} \\mathbb{E}_{q(x_\\sigma \\mid x)} \\left\\| \\mathbf{s}_{\\theta, \\sigma}(\\mathbf{x}_\\sigma) - \\nabla_{\\mathbf{x}_\\sigma} \\log q(\\mathbf{x}_\\sigma \\mid \\mathbf{x}) \\right\\|_2^2 + \\text{const}(\\theta) \\rightarrow \\min_{\\theta}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad20ff3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then to sample we can use **Langevin dynamics** to sample from it:\n",
    "$$\n",
    "\\mathbf{x}_l = \\mathbf{x}_{l-1} + \\frac{\\eta_t}{2} \\mathbf{s}_{\\theta, \\sigma}(\\mathbf{x}_l) + \\sqrt{\\eta_t} \\cdot \\boldsymbol{\\epsilon}_l,\n",
    "$$\n",
    "where $\\boldsymbol{\\epsilon}_l \\sim \\mathcal{N}(0, \\mathbf{I})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78169ad3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Qustion 1.** What $\\sigma$ should we choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426c76f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With **small** $\\sigma$ the problem comes from **the manifold hypothesis**:\n",
    "\n",
    "> Real-world data tend to concentrate on a *low dimensional manifolds* embedded in a *high dimensional space*. \n",
    "\n",
    "The key challenge is the fact that the estimated score functions are inaccurate in low density regions, where few data points are available for computing the score matching objective.\n",
    "<center><img src=\"pics/inaccurate.png\" width=1200 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc0a5a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When the noise magnitude is sufficiently large, it can populate low data density regions to improve the accuracy of estimated scores.\n",
    "<center><img src=\"pics/accurate.png\" width=1200 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e75000",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Qustion 2.** How to change training and sampling to improve quality?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec433a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To achieve the best of both worlds, we use multiple scales of noise perturbations **simultaneously**.\n",
    "\n",
    "### Training\n",
    "1. Get the sample $\\mathbf{x}_0 \\sim \\pi(\\mathbf{x})$.\n",
    "2. Sample noise level $t \\sim \\mathcal{U}\\{1, T\\}$ and the noise $\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\mathbf{I})$.\n",
    "3. Get noisy image $\\mathbf{x}_t = \\mathbf{x}_0 + \\sigma_t \\cdot \\boldsymbol{\\epsilon}$.\n",
    "4. Compute loss $\\mathcal{L} = \\sigma_t^2 \\cdot \\left\\| \\mathbf{s}_{\\theta, \\sigma_t}(\\mathbf{x}_t) + \\frac{\\boldsymbol{\\epsilon}}{\\sigma_t} \\right\\|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f941d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sampling\n",
    "\n",
    "1. **Sample** $\\mathbf{x}_0 \\sim \\mathcal{N}(0, \\sigma_T^2 \\cdot \\mathbf{I}) \\approx q(\\mathbf{x}_T)$.\n",
    "2. **Apply** $L$ steps of Langevin dynamic:\n",
    "\n",
    "  $$\n",
    "  \\mathbf{x}_l = \\mathbf{x}_{l-1} + \\frac{\\eta_t}{2} \\cdot \\mathbf{s}_{\\theta, \\sigma_t}(\\mathbf{x}_{l-1}) + \\sqrt{\\eta_t} \\cdot \\boldsymbol{\\epsilon}_l\n",
    "  $$\n",
    "\n",
    "3. **Update** $\\mathbf{x}_0 := \\mathbf{x}_L$ and choose the next $\\sigma_t$.\n",
    "<center><img src=\"pics/ald.gif\" width=1200 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975597b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Note!**\n",
    "\n",
    "To condition our score model $\\mathbf{s}_{\\theta, \\sigma_t}(\\mathbf{x}_t)$ on $\\sigma_t$ we add addtitional input to the model $\\mathbf{s}_{\\theta, \\sigma_t}(\\mathbf{x}_t, t)$. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ee1f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class ConditionedResnetBlock(nn.Module):\n",
    "    def __init__(self, dim: int, num_embeddings: int) -> None:\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "        )\n",
    "        self.dim = dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        time_embed = self.embedding(y).view(-1, self.dim, 1, 1)\n",
    "        return x + self.block(x + time_embed)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
